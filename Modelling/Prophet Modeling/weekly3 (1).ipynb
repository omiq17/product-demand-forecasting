{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc902c0-08ce-4311-9943-f5a100ab9343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially selected top 3 categories: [\"Men's Fashion\", 'Mobiles & Tablets', 'Superstore']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:05:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:05:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:05:22 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Men's Fashion] forecast done → C:/Users/User/Downloads/PRINCIPLES OF DATA SCIENCE/Datasets/Final-output\\Men's Fashion_forecast.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:05:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:05:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mobiles & Tablets] forecast done → C:/Users/User/Downloads/PRINCIPLES OF DATA SCIENCE/Datasets/Final-output\\Mobiles & Tablets_forecast.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:05:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Superstore] forecast done → C:/Users/User/Downloads/PRINCIPLES OF DATA SCIENCE/Datasets/Final-output\\Superstore_forecast.png\n",
      "\n",
      "=== SUMMARY ===\n",
      "         Category      MAE     RMSE  MAPE (%)\n",
      "    Men's Fashion 0.157888 0.177255 19.686766\n",
      "Mobiles & Tablets 0.092438 0.105212 11.601516\n",
      "       Superstore 0.063899 0.071456  7.469586\n",
      "\n",
      "Metrics saved to: C:/Users/User/Downloads/PRINCIPLES OF DATA SCIENCE/Datasets/Final-output\\forecast_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# === File paths ===\n",
    "data_path = \"C:/Users/User/Downloads/PRINCIPLES OF DATA SCIENCE/Datasets/e-commerce-scrubbed-data-filtered.xlsx\"\n",
    "output_dir = \"C:/Users/User/Downloads/PRINCIPLES OF DATA SCIENCE/Datasets/Final-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Load & preprocess ===\n",
    "df = pd.read_excel(data_path)\n",
    "df = df.dropna(subset=[\"category_name_1\", \"M-Y\", \"qty_ordered\"])\n",
    "df[\"M-Y\"] = pd.to_datetime(df[\"M-Y\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"M-Y\"])\n",
    "\n",
    "# **Keep Weekly Aggregation**\n",
    "df[\"Week\"] = df[\"M-Y\"].dt.to_period(\"W-SUN\").dt.to_timestamp()\n",
    "weekly = df.groupby([\"Week\", \"category_name_1\"])[\"qty_ordered\"].sum().reset_index()\n",
    "\n",
    "# **Expanded Outlier Filtering (Top 15%)**\n",
    "q85 = weekly[\"qty_ordered\"].quantile(0.85)  # Remove top 15% extreme values\n",
    "weekly = weekly[weekly[\"qty_ordered\"] < q85]\n",
    "\n",
    "# **Apply Log Scaling for Stability**\n",
    "weekly[\"qty_ordered\"] = np.log1p(weekly[\"qty_ordered\"])\n",
    "\n",
    "# **Min-Max Scaling**\n",
    "scaler = MinMaxScaler()\n",
    "weekly[\"qty_ordered\"] = scaler.fit_transform(weekly[[\"qty_ordered\"]])\n",
    "\n",
    "# **Apply Moving Average for Smoothing**\n",
    "weekly[\"qty_ordered\"] = weekly[\"qty_ordered\"].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Select top 3 categories by total quantity\n",
    "top_categories = (\n",
    "    weekly.groupby(\"category_name_1\")[\"qty_ordered\"].sum().nlargest(3).index.tolist()\n",
    ")\n",
    "print(f\"Initially selected top 3 categories: {top_categories}\")\n",
    "\n",
    "# Ensure they have enough historical data\n",
    "train_weeks = 120  # Increased training period\n",
    "horizon = 6\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for cat in top_categories:\n",
    "    sub = weekly[weekly[\"category_name_1\"] == cat].sort_values(\"Week\").reset_index(drop=True)\n",
    "    sub.rename(columns={\"Week\": \"ds\", \"qty_ordered\": \"y\"}, inplace=True)\n",
    "\n",
    "    # Forecast on available data instead of skipping\n",
    "    train_df = sub.iloc[:-horizon].copy()\n",
    "    test_df = sub.iloc[-horizon:].copy()\n",
    "\n",
    "    model = Prophet(weekly_seasonality=True, changepoint_prior_scale=0.00005)  # Fine-tuned model\n",
    "    model.fit(train_df)\n",
    "\n",
    "    forecast = model.predict(test_df[[\"ds\"]])\n",
    "    df_pred = forecast[[\"ds\", \"yhat\"]].merge(test_df, on=\"ds\")\n",
    "\n",
    "    mae = mean_absolute_error(df_pred[\"y\"], df_pred[\"yhat\"])\n",
    "    rmse = np.sqrt(mean_squared_error(df_pred[\"y\"], df_pred[\"yhat\"]))\n",
    "    \n",
    "    # **Switch to MAPE Instead of SMAPE**\n",
    "    mape = (np.abs(df_pred[\"y\"] - df_pred[\"yhat\"]) / df_pred[\"y\"]).mean() * 100\n",
    "\n",
    "    metrics.append({\"Category\": cat, \"MAE\": mae, \"RMSE\": rmse, \"MAPE (%)\": mape})\n",
    "\n",
    "    # Plot with Improved Readability\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_df[\"ds\"], train_df[\"y\"], \"-o\", label=\"Train Data\", color=\"blue\")\n",
    "    plt.plot(test_df[\"ds\"], test_df[\"y\"], \"-o\", label=\"Actual Demand\", color=\"green\")\n",
    "    plt.plot(df_pred[\"ds\"], df_pred[\"yhat\"], \"--x\", label=\"Forecasted Demand\", color=\"red\")\n",
    "    \n",
    "    # **Enhance Readability**\n",
    "    plt.axvline(train_df[\"ds\"].max(), color=\"black\", linestyle=\":\", label=\"Train-Test Split\")\n",
    "    plt.xlabel(\"Week\")\n",
    "    plt.ylabel(\"Weekly Demand (Normalized)\")\n",
    "    plt.title(f\"{cat}: Weekly Demand Forecast ({train_weeks}w Train / {horizon}w Test)\")\n",
    "    \n",
    "    # **Grid Lines for Clarity**\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # **Add Annotation for Highest Peak**\n",
    "    peak_week = df_pred.loc[df_pred[\"yhat\"].idxmax()]\n",
    "    plt.annotate(\"Highest Forecasted Demand\", xy=(peak_week[\"ds\"], peak_week[\"yhat\"]), \n",
    "                 xytext=(peak_week[\"ds\"], peak_week[\"yhat\"] * 1.1),\n",
    "                 arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_path = os.path.join(output_dir, f\"{cat}_forecast.png\")\n",
    "    plt.savefig(fig_path)\n",
    "    plt.close()\n",
    "    print(f\"[{cat}] forecast done → {fig_path}\")\n",
    "\n",
    "# === Save summary ===\n",
    "if metrics:\n",
    "    dfm = pd.DataFrame(metrics)\n",
    "    excel_path = os.path.join(output_dir, \"forecast_metrics.xlsx\")\n",
    "    dfm.to_excel(excel_path, index=False)\n",
    "\n",
    "    # Print Summary\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(dfm.to_string(index=False))\n",
    "    print(f\"\\nMetrics saved to: {excel_path}\")\n",
    "else:\n",
    "    print(\"No forecasts generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52a9f9d-334e-4988-8ec1-a7d12531cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast dates: [Timestamp('2018-02-26 00:00:00'), Timestamp('2018-03-26 00:00:00'), Timestamp('2018-04-30 00:00:00'), Timestamp('2018-05-28 00:00:00'), Timestamp('2018-06-25 00:00:00'), Timestamp('2018-07-30 00:00:00')]\n",
      "Test dates: [Timestamp('2018-02-26 00:00:00'), Timestamp('2018-03-26 00:00:00'), Timestamp('2018-04-30 00:00:00'), Timestamp('2018-05-28 00:00:00'), Timestamp('2018-06-25 00:00:00'), Timestamp('2018-07-30 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Forecast dates:\", forecast['ds'].tail(10).to_list())\n",
    "print(\"Test dates:\", test_df['ds'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec28a3c-23c0-4f9f-87ac-b07be6356cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130653 entries, 0 to 130652\n",
      "Data columns (total 20 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   item_id          130653 non-null  int64         \n",
      " 1   status           130653 non-null  object        \n",
      " 2   created_at       130653 non-null  datetime64[ns]\n",
      " 3   sku              130653 non-null  object        \n",
      " 4   price            130653 non-null  float64       \n",
      " 5   qty_ordered      130653 non-null  int64         \n",
      " 6   grand_total      130653 non-null  float64       \n",
      " 7   increment_id     130653 non-null  int64         \n",
      " 8   category_name_1  130653 non-null  object        \n",
      " 9   discount_amount  130653 non-null  float64       \n",
      " 10  payment_method   130653 non-null  object        \n",
      " 11  BI Status        130653 non-null  object        \n",
      " 12  Year             130653 non-null  int64         \n",
      " 13  Month            130653 non-null  int64         \n",
      " 14  Customer Since   130653 non-null  object        \n",
      " 15  M-Y              130653 non-null  datetime64[ns]\n",
      " 16  FY               130653 non-null  object        \n",
      " 17  Customer ID      130653 non-null  int64         \n",
      " 18  Paid total       130653 non-null  float64       \n",
      " 19  Week             130653 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(4), int64(6), object(7)\n",
      "memory usage: 19.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
